{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592     Wisconsin, Ohio, California and 10 other state...\n",
      "4048     President Donald Trump on Wednesday attacked a...\n",
      "13063    Venezuela s powerful former oil czar Rafael Ra...\n",
      "13383    Emperor Akihito, who has spent much of his nea...\n",
      "11631    Lebanese Prime Minister Saad al-Hariri said on...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Merge True and Fake News Data \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer\n",
    "true = pd.read_csv(\"True.csv\")\n",
    "fake = pd.read_csv(\"Fake.csv\")\n",
    "true[\"label\"]  = 0\n",
    "fake[\"label\"] = 1 #using 1 for fake since we want to detect fake news\n",
    "\n",
    "sample_true = true.sample(n=5000)\n",
    "sample_true['text'] = sample_true['text'].astype(str)\n",
    "sample_true['text'] = sample_true['text'].apply(lambda x: x.split(' - ', 1)[1] if isinstance(x, str) and ' - ' in x else x)\n",
    "\n",
    "\n",
    "sample_fake = fake.sample(n=5000)\n",
    "\n",
    "print(sample_true['text'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_false = fake.sample(n=5000)\n",
    "\n",
    "df = pd.concat([sample_true,sample_fake])\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = NewsDataset(train_encodings, train_labels.tolist())\n",
    "val_dataset = NewsDataset(val_encodings, val_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\syedo\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2416555397486fa36522155ba05ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6883, 'grad_norm': 2.1348206996917725, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.02}\n",
      "{'loss': 0.6918, 'grad_norm': 1.1100388765335083, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.04}\n",
      "{'loss': 0.6785, 'grad_norm': 1.9762234687805176, 'learning_rate': 3e-06, 'epoch': 0.06}\n",
      "{'loss': 0.6779, 'grad_norm': 1.4350132942199707, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 0.656, 'grad_norm': 1.3762658834457397, 'learning_rate': 5e-06, 'epoch': 0.1}\n",
      "{'loss': 0.6115, 'grad_norm': 2.3143560886383057, 'learning_rate': 6e-06, 'epoch': 0.12}\n",
      "{'loss': 0.511, 'grad_norm': 3.2735044956207275, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 0.3869, 'grad_norm': 2.989393949508667, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 0.2709, 'grad_norm': 2.673880100250244, 'learning_rate': 9e-06, 'epoch': 0.18}\n",
      "{'loss': 0.2154, 'grad_norm': 4.164487361907959, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1667, 'grad_norm': 7.011040687561035, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1467, 'grad_norm': 1.8795897960662842, 'learning_rate': 1.2e-05, 'epoch': 0.24}\n",
      "{'loss': 0.083, 'grad_norm': 1.2474629878997803, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0598, 'grad_norm': 11.587897300720215, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1265, 'grad_norm': 13.76810359954834, 'learning_rate': 1.5e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0231, 'grad_norm': 0.21174222230911255, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0521, 'grad_norm': 0.1369500756263733, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0768, 'grad_norm': 10.274113655090332, 'learning_rate': 1.8e-05, 'epoch': 0.36}\n",
      "{'loss': 0.057, 'grad_norm': 17.200393676757812, 'learning_rate': 1.9e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0639, 'grad_norm': 0.2931341826915741, 'learning_rate': 2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1201, 'grad_norm': 0.46537625789642334, 'learning_rate': 2.1e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0067, 'grad_norm': 0.06477981060743332, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0309, 'grad_norm': 0.050951629877090454, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.46}\n",
      "{'loss': 0.1147, 'grad_norm': 0.1592521369457245, 'learning_rate': 2.4e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0252, 'grad_norm': 0.1261839121580124, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0307, 'grad_norm': 2.6874523162841797, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0293, 'grad_norm': 0.037977248430252075, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0053, 'grad_norm': 0.0361015610396862, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0083, 'grad_norm': 0.07464737445116043, 'learning_rate': 2.9e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0995, 'grad_norm': 0.15259775519371033, 'learning_rate': 3e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0319, 'grad_norm': 8.219338417053223, 'learning_rate': 3.1e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0039, 'grad_norm': 0.05086850747466087, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0589, 'grad_norm': 0.02536410465836525, 'learning_rate': 3.3e-05, 'epoch': 0.66}\n",
      "{'loss': 0.057, 'grad_norm': 28.3839111328125, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0426, 'grad_norm': 1.634951114654541, 'learning_rate': 3.5e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0137, 'grad_norm': 0.08325854688882828, 'learning_rate': 3.6e-05, 'epoch': 0.72}\n",
      "{'loss': 0.1181, 'grad_norm': 14.589322090148926, 'learning_rate': 3.7e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0435, 'grad_norm': 0.4363537132740021, 'learning_rate': 3.8e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1053, 'grad_norm': 0.04440157487988472, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0358, 'grad_norm': 0.8156917691230774, 'learning_rate': 4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1136, 'grad_norm': 0.08448462933301926, 'learning_rate': 4.1e-05, 'epoch': 0.82}\n",
      "{'loss': 0.064, 'grad_norm': 0.03177468478679657, 'learning_rate': 4.2e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0635, 'grad_norm': 0.19080066680908203, 'learning_rate': 4.3e-05, 'epoch': 0.86}\n",
      "{'loss': 0.0256, 'grad_norm': 0.5610632300376892, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0184, 'grad_norm': 0.8504382967948914, 'learning_rate': 4.5e-05, 'epoch': 0.9}\n",
      "{'loss': 0.005, 'grad_norm': 0.010942013002932072, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0007, 'grad_norm': 0.011686015874147415, 'learning_rate': 4.7e-05, 'epoch': 0.94}\n",
      "{'loss': 0.102, 'grad_norm': 0.013830655254423618, 'learning_rate': 4.8e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0028, 'grad_norm': 0.016531875357031822, 'learning_rate': 4.9e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0015, 'grad_norm': 2.0964181423187256, 'learning_rate': 5e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce13a5e9a9d4360aa8ec4e5e5115abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03877260163426399, 'eval_runtime': 33.7642, 'eval_samples_per_second': 59.234, 'eval_steps_per_second': 3.702, 'epoch': 1.0}\n",
      "{'loss': 0.0327, 'grad_norm': 0.011079901829361916, 'learning_rate': 4.9500000000000004e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0395, 'grad_norm': 0.00945274531841278, 'learning_rate': 4.9e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0216, 'grad_norm': 0.021577244624495506, 'learning_rate': 4.85e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0007, 'grad_norm': 0.020690683275461197, 'learning_rate': 4.8e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0009, 'grad_norm': 0.023781199008226395, 'learning_rate': 4.75e-05, 'epoch': 1.1}\n",
      "{'loss': 0.049, 'grad_norm': 0.008982961066067219, 'learning_rate': 4.7e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0515, 'grad_norm': 0.018898945301771164, 'learning_rate': 4.6500000000000005e-05, 'epoch': 1.14}\n",
      "{'loss': 0.1168, 'grad_norm': 0.036860279738903046, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0043, 'grad_norm': 2.6860997676849365, 'learning_rate': 4.55e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0662, 'grad_norm': 8.853404998779297, 'learning_rate': 4.5e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0804, 'grad_norm': 0.03499976918101311, 'learning_rate': 4.4500000000000004e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0318, 'grad_norm': 0.0226886048913002, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0016, 'grad_norm': 0.020070984959602356, 'learning_rate': 4.35e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0098, 'grad_norm': 0.017059052363038063, 'learning_rate': 4.3e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0746, 'grad_norm': 0.03585287928581238, 'learning_rate': 4.25e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0194, 'grad_norm': 0.02752424217760563, 'learning_rate': 4.2e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0387, 'grad_norm': 0.044112320989370346, 'learning_rate': 4.15e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0257, 'grad_norm': 0.027995586395263672, 'learning_rate': 4.1e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0152, 'grad_norm': 0.02142571471631527, 'learning_rate': 4.05e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0131, 'grad_norm': 0.018243182450532913, 'learning_rate': 4e-05, 'epoch': 1.4}\n",
      "{'loss': 0.001, 'grad_norm': 0.37663713097572327, 'learning_rate': 3.9500000000000005e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0505, 'grad_norm': 25.40741729736328, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0061, 'grad_norm': 0.009714322164654732, 'learning_rate': 3.85e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0033, 'grad_norm': 0.4699820876121521, 'learning_rate': 3.8e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0091, 'grad_norm': 12.122560501098633, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0566, 'grad_norm': 0.010906850919127464, 'learning_rate': 3.7e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0465, 'grad_norm': 0.009843257255852222, 'learning_rate': 3.65e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0005, 'grad_norm': 0.012237587943673134, 'learning_rate': 3.6e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0159, 'grad_norm': 0.009868530556559563, 'learning_rate': 3.55e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0022, 'grad_norm': 0.009613225236535072, 'learning_rate': 3.5e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0738, 'grad_norm': 0.04020019248127937, 'learning_rate': 3.45e-05, 'epoch': 1.62}\n",
      "{'loss': 0.046, 'grad_norm': 6.475684642791748, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.64}\n",
      "{'loss': 0.0159, 'grad_norm': 0.06849208474159241, 'learning_rate': 3.35e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0098, 'grad_norm': 0.01860657148063183, 'learning_rate': 3.3e-05, 'epoch': 1.68}\n",
      "{'loss': 0.0007, 'grad_norm': 0.008529389277100563, 'learning_rate': 3.2500000000000004e-05, 'epoch': 1.7}\n",
      "{'loss': 0.0061, 'grad_norm': 10.33588695526123, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.72}\n",
      "{'loss': 0.0501, 'grad_norm': 0.00971970148384571, 'learning_rate': 3.15e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0204, 'grad_norm': 0.007696210872381926, 'learning_rate': 3.1e-05, 'epoch': 1.76}\n",
      "{'loss': 0.0024, 'grad_norm': 0.008463256992399693, 'learning_rate': 3.05e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0032, 'grad_norm': 0.008067521266639233, 'learning_rate': 3e-05, 'epoch': 1.8}\n",
      "{'loss': 0.0004, 'grad_norm': 0.008990896865725517, 'learning_rate': 2.95e-05, 'epoch': 1.82}\n",
      "{'loss': 0.0033, 'grad_norm': 0.006088764872401953, 'learning_rate': 2.9e-05, 'epoch': 1.84}\n",
      "{'loss': 0.0226, 'grad_norm': 0.5373216271400452, 'learning_rate': 2.8499999999999998e-05, 'epoch': 1.86}\n",
      "{'loss': 0.0318, 'grad_norm': 0.005537087097764015, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0371, 'grad_norm': 10.564212799072266, 'learning_rate': 2.7500000000000004e-05, 'epoch': 1.9}\n",
      "{'loss': 0.002, 'grad_norm': 0.017274152487516403, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.92}\n",
      "{'loss': 0.1089, 'grad_norm': 0.008409234695136547, 'learning_rate': 2.6500000000000004e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0035, 'grad_norm': 0.016966940835118294, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0021, 'grad_norm': 0.028710046783089638, 'learning_rate': 2.5500000000000003e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0004, 'grad_norm': 0.005342175718396902, 'learning_rate': 2.5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5571bdc1466442549d0bc4d7347d12a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014872394502162933, 'eval_runtime': 34.349, 'eval_samples_per_second': 58.226, 'eval_steps_per_second': 3.639, 'epoch': 2.0}\n",
      "{'loss': 0.0004, 'grad_norm': 0.008482244797050953, 'learning_rate': 2.45e-05, 'epoch': 2.02}\n",
      "{'loss': 0.0004, 'grad_norm': 0.005281701683998108, 'learning_rate': 2.4e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0004, 'grad_norm': 0.017311103641986847, 'learning_rate': 2.35e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0003, 'grad_norm': 0.004934926051646471, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0351, 'grad_norm': 0.006347563583403826, 'learning_rate': 2.25e-05, 'epoch': 2.1}\n",
      "{'loss': 0.0003, 'grad_norm': 0.005840738769620657, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0003, 'grad_norm': 0.005816238932311535, 'learning_rate': 2.15e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0047832331620156765, 'learning_rate': 2.1e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004353512544184923, 'learning_rate': 2.05e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0004, 'grad_norm': 0.007606382481753826, 'learning_rate': 2e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004297179635614157, 'learning_rate': 1.9500000000000003e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0003, 'grad_norm': 0.005097195040434599, 'learning_rate': 1.9e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0189, 'grad_norm': 22.812349319458008, 'learning_rate': 1.85e-05, 'epoch': 2.26}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004555867053568363, 'learning_rate': 1.8e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0002, 'grad_norm': 0.00482745049521327, 'learning_rate': 1.75e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004319488070905209, 'learning_rate': 1.7000000000000003e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0038284421898424625, 'learning_rate': 1.65e-05, 'epoch': 2.34}\n",
      "{'loss': 0.0002, 'grad_norm': 0.005007393192499876, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003740813350304961, 'learning_rate': 1.55e-05, 'epoch': 2.38}\n",
      "{'loss': 0.0459, 'grad_norm': 0.0034899276215583086, 'learning_rate': 1.5e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004189739003777504, 'learning_rate': 1.45e-05, 'epoch': 2.42}\n",
      "{'loss': 0.0008, 'grad_norm': 0.0036214650608599186, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0033960246946662664, 'learning_rate': 1.3500000000000001e-05, 'epoch': 2.46}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0036751481238752604, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.48}\n",
      "{'loss': 0.0003, 'grad_norm': 0.003965903073549271, 'learning_rate': 1.25e-05, 'epoch': 2.5}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004700299818068743, 'learning_rate': 1.2e-05, 'epoch': 2.52}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004053536802530289, 'learning_rate': 1.1500000000000002e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0182, 'grad_norm': 0.00917898491024971, 'learning_rate': 1.1000000000000001e-05, 'epoch': 2.56}\n",
      "{'loss': 0.0002, 'grad_norm': 0.008435489609837532, 'learning_rate': 1.05e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0035937237553298473, 'learning_rate': 1e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0002, 'grad_norm': 0.005188824608922005, 'learning_rate': 9.5e-06, 'epoch': 2.62}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004054914228618145, 'learning_rate': 9e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003617682959884405, 'learning_rate': 8.500000000000002e-06, 'epoch': 2.66}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0028941200580447912, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0032959184609353542, 'learning_rate': 7.5e-06, 'epoch': 2.7}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003422550391405821, 'learning_rate': 7.000000000000001e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0002, 'grad_norm': 0.002691281493753195, 'learning_rate': 6.5000000000000004e-06, 'epoch': 2.74}\n",
      "{'loss': 0.0007, 'grad_norm': 0.0031254992354661226, 'learning_rate': 6e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0030078310519456863, 'learning_rate': 5.500000000000001e-06, 'epoch': 2.78}\n",
      "{'loss': 0.0107, 'grad_norm': 0.002795630367472768, 'learning_rate': 5e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003117013955488801, 'learning_rate': 4.5e-06, 'epoch': 2.82}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0032039559446275234, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0026574989315122366, 'learning_rate': 3.5000000000000004e-06, 'epoch': 2.86}\n",
      "{'loss': 0.0002, 'grad_norm': 0.004071967676281929, 'learning_rate': 3e-06, 'epoch': 2.88}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0027904699090868235, 'learning_rate': 2.5e-06, 'epoch': 2.9}\n",
      "{'loss': 0.0002, 'grad_norm': 0.002734656445682049, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.92}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003315248293802142, 'learning_rate': 1.5e-06, 'epoch': 2.94}\n",
      "{'loss': 0.0003, 'grad_norm': 0.002622042316943407, 'learning_rate': 1.0000000000000002e-06, 'epoch': 2.96}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0024369352031499147, 'learning_rate': 5.000000000000001e-07, 'epoch': 2.98}\n",
      "{'loss': 0.0008, 'grad_norm': 0.00259423372335732, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d991687d4cc4e2785467adc64e302a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01495737861841917, 'eval_runtime': 32.886, 'eval_samples_per_second': 60.816, 'eval_steps_per_second': 3.801, 'epoch': 3.0}\n",
      "{'train_runtime': 1178.7813, 'train_samples_per_second': 20.36, 'train_steps_per_second': 1.273, 'train_loss': 0.06059499291516841, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.06059499291516841, metrics={'train_runtime': 1178.7813, 'train_samples_per_second': 20.36, 'train_steps_per_second': 1.273, 'total_flos': 3179217567744000.0, 'train_loss': 0.06059499291516841, 'epoch': 3.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import accelerate\n",
    "\n",
    "# Load model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f67f69fe6544d18e6e206126f82d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.01495737861841917, 'eval_runtime': 36.0316, 'eval_samples_per_second': 55.507, 'eval_steps_per_second': 3.469, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fake_news_model\\\\tokenizer_config.json',\n",
       " './fake_news_model\\\\special_tokens_map.json',\n",
       " './fake_news_model\\\\vocab.txt',\n",
       " './fake_news_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('./fake_news_model')\n",
    "tokenizer.save_pretrained('./fake_news_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is classified as Fake News.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = './fake_news_model'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Define the input text\n",
    "input_text =\"Republicans in Texas, including Gov. Greg Abbott, ripped into the new $44 billion White House disaster relief aid request as  inadequate.  It s been two months since the state was devastated by Hurricane Harvey and Donald Trump has failed on his promise to rebuild Texas. Abbott s criticism is strikingly different than the day after Trump visited Texas in the aftermath of the hurricane. His commitment was firm, strong and unequivocal,  Abbott said at the time.  That he was going to do everything he could to ensure that Texas will be restored as swiftly, as effectively as possible. But now, two months later, Republicans are calling the response  wholly inadequate,  according to the Dallas News.The White House disaster relief aid request falls well short of the demands made by officials from Texas, Florida and Puerto Rico.Greg Abbott said that the request  does not live up  to what Trump pledged in recovery aid. Abbott noted during a news conference that he s still reviewing the White House request but that it appears to be  completely inadequate.  What s more, Abbott said, it  does not live up  to what Trump has pledged in recovery aid, then he said that Washington worked faster for victims of Superstorm Sandy than for Harvey. Superstorm Sandy hit in 2012 during the Obama administration, by the way. The president has told me privately what he said publicly, and that is he wants to be the builder president. The president has said he wants this to be the best recovery from a disaster ever,  Abbott said.It s not just Abbott. Texas Sen. John Cornyn, the No. 2 Republican, blasted the request as  wholly inadequate.  A chorus of Texas lawmakers slammed it as insufficient.Houston Rep. John Culberson, a Republican and appropriations committee member, ripped Trump s recovery efforts, calling the request a  complete lack of understanding of the fundamental needs of Texans  and said it is a  nightmare  for Harvey survivors.Democrats, too, including Senate Minority Leader Chuck Schumer\"\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the predicted label\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Interpret the results\n",
    "label = predictions.item()\n",
    "if label == 1:\n",
    "    print(\"The text is classified as Fake News.\")\n",
    "else:\n",
    "    print(\"The text is classified as True News.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House panel subpoenas New York, Massachusetts ...</td>\n",
       "      <td>WASHINGTON (Reuters) - A U.S. House of Represe...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 13, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syria investigator del Ponte signs off with a ...</td>\n",
       "      <td>GENEVA (Reuters) - Veteran prosecutor Carla de...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 18, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phoenix Mayor Calls On Justice Department To ...</td>\n",
       "      <td>Phoenix mayor Greg Stanton is calling on the U...</td>\n",
       "      <td>News</td>\n",
       "      <td>March 24, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WATCH: 5 Straight Minutes Of Donald Trump Lyi...</td>\n",
       "      <td>There s a lot of uncertainties in this electio...</td>\n",
       "      <td>News</td>\n",
       "      <td>August 16, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marriott Hotel Shoots Back Response After Musl...</td>\n",
       "      <td>A Muslim activist group  has pushed Marriott I...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Sep 22, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>MUSLIM ACTIVISTS LAUNCH VOTER REGISTRATION DRI...</td>\n",
       "      <td>Who would ve guessed? A coalition of U.S.-base...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Dec 23, 2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>Jakarta closes hotel targeted by Islamists for...</td>\n",
       "      <td>JAKARTA (Reuters) - Indonesia s capital has sh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>Democrat Hilariously Mocks Paul Ryan During H...</td>\n",
       "      <td>On Wednesday, the Democratic party staged a po...</td>\n",
       "      <td>News</td>\n",
       "      <td>June 22, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>Trumpsters Launch Insane Conspiracy Theory Ab...</td>\n",
       "      <td>Senator John McCain (R-AZ) was treated at Walt...</td>\n",
       "      <td>News</td>\n",
       "      <td>November 23, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>Col. Ralph Peters On Obamaâ€™s Refusal To Live I...</td>\n",
       "      <td>Peters is dead on in his description of Obama ...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Oct 13, 2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      House panel subpoenas New York, Massachusetts ...   \n",
       "1      Syria investigator del Ponte signs off with a ...   \n",
       "2       Phoenix Mayor Calls On Justice Department To ...   \n",
       "3       WATCH: 5 Straight Minutes Of Donald Trump Lyi...   \n",
       "4      Marriott Hotel Shoots Back Response After Musl...   \n",
       "...                                                  ...   \n",
       "44893  MUSLIM ACTIVISTS LAUNCH VOTER REGISTRATION DRI...   \n",
       "44894  Jakarta closes hotel targeted by Islamists for...   \n",
       "44895   Democrat Hilariously Mocks Paul Ryan During H...   \n",
       "44896   Trumpsters Launch Insane Conspiracy Theory Ab...   \n",
       "44897  Col. Ralph Peters On Obamaâ€™s Refusal To Live I...   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "0      WASHINGTON (Reuters) - A U.S. House of Represe...     politicsNews   \n",
       "1      GENEVA (Reuters) - Veteran prosecutor Carla de...        worldnews   \n",
       "2      Phoenix mayor Greg Stanton is calling on the U...             News   \n",
       "3      There s a lot of uncertainties in this electio...             News   \n",
       "4      A Muslim activist group  has pushed Marriott I...         politics   \n",
       "...                                                  ...              ...   \n",
       "44893  Who would ve guessed? A coalition of U.S.-base...  Government News   \n",
       "44894  JAKARTA (Reuters) - Indonesia s capital has sh...        worldnews   \n",
       "44895  On Wednesday, the Democratic party staged a po...             News   \n",
       "44896  Senator John McCain (R-AZ) was treated at Walt...             News   \n",
       "44897  Peters is dead on in his description of Obama ...  Government News   \n",
       "\n",
       "                      date  label  \n",
       "0           July 13, 2016       0  \n",
       "1      September 18, 2017       0  \n",
       "2           March 24, 2016      1  \n",
       "3          August 16, 2016      1  \n",
       "4             Sep 22, 2017      1  \n",
       "...                    ...    ...  \n",
       "44893         Dec 23, 2015      1  \n",
       "44894    October 30, 2017       0  \n",
       "44895        June 22, 2016      1  \n",
       "44896    November 23, 2017      1  \n",
       "44897         Oct 13, 2015      1  \n",
       "\n",
       "[44898 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "CUDA device count: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA current device:\", torch.cuda.current_device())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
